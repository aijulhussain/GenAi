{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2a00ff",
   "metadata": {},
   "source": [
    "### LLM powered chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9be03573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e92bdbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F4D310F9A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F4D326BB80>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model= ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb5591fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Aijul, it's nice to meet you!\\n\\nThat's awesome, Data Science is a fascinating field.  \\n\\nWhat kind of data science work are you involved in? Are you working on any interesting projects right now?  \\n\\nI'm always eager to learn more about what people are doing in this area.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 23, 'total_tokens': 94, 'completion_time': 0.129090909, 'prompt_time': 0.002053618, 'queue_time': 0.24442804599999998, 'total_time': 0.131144527}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--56b6e3b0-0532-4348-875e-c06f87e54d18-0', usage_metadata={'input_tokens': 23, 'output_tokens': 71, 'total_tokens': 94})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hi, My name is Aijul and I am a DATA Scientist\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e33802bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Aijul, and you are a Data Scientist!  \\n\\nI remember that from our earlier conversation. üòä  \\n\\nIs there anything else you'd like to talk about?  Perhaps you could tell me about a project you're working on?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 101, 'total_tokens': 157, 'completion_time': 0.101818182, 'prompt_time': 0.004956476, 'queue_time': 0.243373897, 'total_time': 0.106774658}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--4ae22370-9db2-4e3e-adb7-9b7d51dc3ea2-0', usage_metadata={'input_tokens': 101, 'output_tokens': 56, 'total_tokens': 157})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Aijul and I am a DATA Scientist\"),\n",
    "        AIMessage(content=\"Hello Aijul, it's nice to meet you! \\n\\nBeing a Data Scientist is an exciting field. What kind of projects are you currently working on?\\n\\nI'm eager to learn more about your work and maybe even discuss some data science topics with you.  \\n\\n\"),\n",
    "        HumanMessage(content=\"hey, whats my name and what i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab81870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.66)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.10.0)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "## message history\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "adfa79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]= ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "009bc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83a28db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Aijul and I am a DATA Scientist\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05121597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Aijul, it's nice to meet you! \\n\\nIt's great to know you're a data scientist. That's a fascinating field.  \\n\\nWhat kind of data science work are you involved in? Perhaps you could tell me about a project you're particularly proud of, or a challenge you're currently facing. I'm always eager to learn more about what people are doing in this area.\\n\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4e396114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Aijul.  \\n\\nYou told me at the beginning of our conversation! üòä  \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 127, 'total_tokens': 152, 'completion_time': 0.045454545, 'prompt_time': 0.008212113, 'queue_time': 0.29270159599999995, 'total_time': 0.053666658}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--205d134c-beb9-46bb-bb55-c615fd5aea2e-0', usage_metadata={'input_tokens': 127, 'output_tokens': 25, 'total_tokens': 152})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"what is my name\")],\n",
    "        config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3e37820",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "87ead7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a helpful assistant. Answer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036cab6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0dd19491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Aijul, it's nice to meet you!\\n\\nI'm happy to help with any questions you have. Just ask away! üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 32, 'total_tokens': 67, 'completion_time': 0.063636364, 'prompt_time': 0.002255918, 'queue_time': 0.244969306, 'total_time': 0.065892282}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--87e740de-ee45-40dd-9e27-2090a398fda3-0', usage_metadata={'input_tokens': 32, 'output_tokens': 35, 'total_tokens': 67})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi my name is Aijul\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e908ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8348c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "#add complexity\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a helpful assistant. Answer all the question to the nest of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7df1b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Aijul\")], \"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bef5f085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Aijul!  \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§  üòä\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f9476e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history =RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c7fe09c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§Ö‡§ú‡§Ø, ‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ú‡•ã ‡§≠‡•Ä ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç‡§ó‡•á, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ‡•§  \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üòä\\n\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi, I am Aijul\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76ac9a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§Ö‡§ú‡§Ø ‡§π‡•à, ‡§ú‡•à‡§∏‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§®‡•á ‡§ñ‡•Å‡§¶ ‡§π‡•Ä ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§π‡•à‡•§ üòä  \\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what's my name?\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fb8db9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aijul\\desktop\\gen\\langchain\\venv\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.5 MB 837.5 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.5/10.5 MB 837.5 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 0.8/10.5 MB 817.9 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.0/10.5 MB 853.0 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.0/10.5 MB 853.0 kB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 1.3/10.5 MB 849.7 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.6/10.5 MB 847.3 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.8/10.5 MB 853.0 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.8/10.5 MB 853.0 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.1/10.5 MB 857.1 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.1/10.5 MB 857.1 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.4/10.5 MB 823.4 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.6/10.5 MB 829.6 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.6/10.5 MB 829.6 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.6/10.5 MB 829.6 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.6/10.5 MB 829.6 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 2.9/10.5 MB 726.4 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 3.1/10.5 MB 732.2 kB/s eta 0:00:10\n",
      "   ------------ --------------------------- 3.1/10.5 MB 732.2 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 3.4/10.5 MB 743.0 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 3.7/10.5 MB 754.6 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 3.7/10.5 MB 754.6 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 3.9/10.5 MB 755.3 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 4.2/10.5 MB 762.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 4.5/10.5 MB 771.3 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 4.5/10.5 MB 771.3 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 4.7/10.5 MB 775.0 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.0/10.5 MB 782.4 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.0/10.5 MB 782.4 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.2/10.5 MB 789.0 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.5/10.5 MB 789.5 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.5/10.5 MB 789.5 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 5.8/10.5 MB 786.4 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.0/10.5 MB 790.3 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.0/10.5 MB 790.3 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.3/10.5 MB 794.0 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.6/10.5 MB 797.3 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.8/10.5 MB 800.4 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 6.8/10.5 MB 800.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.1/10.5 MB 797.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.1/10.5 MB 797.4 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.3/10.5 MB 798.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 7.6/10.5 MB 801.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.9/10.5 MB 804.2 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 7.9/10.5 MB 804.2 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.1/10.5 MB 807.9 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.4/10.5 MB 807.6 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.4/10.5 MB 807.6 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 8.7/10.5 MB 809.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 8.9/10.5 MB 813.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.9/10.5 MB 813.0 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.2/10.5 MB 813.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.4/10.5 MB 815.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.4/10.5 MB 815.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 9.4/10.5 MB 815.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 9.7/10.5 MB 800.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.5 MB 799.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.5 MB 799.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.5 MB 800.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 800.9 kB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 837.5 kB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.5/2.4 MB 837.5 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.4 MB 599.2 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.8/2.4 MB 599.2 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 599.0 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 599.0 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 1.3/2.4 MB 645.3 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 645.3 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 1.6/2.4 MB 660.3 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.8/2.4 MB 689.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 720.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 720.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 728.1 kB/s eta 0:00:00\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------- ----------------------------- 2/8 [regex]\n",
      "   --------------- ------------------------ 3/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [filelock]\n",
      "   ------------------------- -------------- 5/8 [huggingface-hub]\n",
      "   ------------------------- -------------- 5/8 [huggingface-hub]\n",
      "   ------------------------- -------------- 5/8 [huggingface-hub]\n",
      "   ------------------------------ --------- 6/8 [tokenizers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ----------------------------------- ---- 7/8 [transformers]\n",
      "   ---------------------------------------- 8/8 [transformers]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.33.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c62037",
   "metadata": {},
   "source": [
    "### manage the conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a9909b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, I am Aijul', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 2+2?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages, HumanMessage, AIMessage\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi, I am Aijul\"),\n",
    "    AIMessage(content=\"Hi\"),\n",
    "    HumanMessage(content=\"Hi, I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"Nice\"),\n",
    "    HumanMessage(content=\"What is 2+2?\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No problem\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47327431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said you like vanilla ice cream! üòä  What's your favorite way to eat it?\\n\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"what ice cream do I like\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d1944ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrap this messages history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config ={\"configurable\": {\"session_id\": \"chat5\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b95328cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and don't know your name. Could you tell me? üòä  \\n\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what's my name?\")],\"language\":\"English\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5450fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf092071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3762c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
